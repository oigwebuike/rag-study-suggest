{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import json\n",
    "import math\n",
    "# import ollama\n",
    "# import requests\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ.LANGCHAIN_TRACING_V2 = True\n",
    "os.environ.LANGCHAIN_ENDPOINT = \"https://api.smith.langchain.com/\"\n",
    "os.environ.LANGCHAIN_API_KEY = os.getenv(\"LANGSMITH_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_body =[\n",
    "     \n",
    "    \"Quantum computing promises to revolutionize data encryption by making previously unsolvable problems computationally feasible.\",\n",
    "    \"Regular exercise, combined with a balanced diet, is key to maintaining both physical and mental well-being.\",\n",
    "    \"The vibrant markets of Marrakech offer a sensory overload, from the scent of spices to the vivid colors of handcrafted textiles.\",\n",
    "    \"Natural Language Processing (NLP) is enabling machines to understand and respond to human language more accurately than ever before.\",\n",
    "    \"Inflation rates can have a profound impact on consumer spending, leading to changes in overall economic growth.\",\n",
    "    \"The concept of cognitive dissonance explains why people sometimes hold onto beliefs even when confronted with contradictory evidence.\",\n",
    "    \"NASA’s Artemis program aims to establish a sustainable human presence on the Moon by the end of the decade.\",\n",
    "    \"The Renaissance was a period of immense cultural, artistic, and intellectual revival that began in Italy in the 14th century.\",\n",
    "    \"Integrating hands-on learning experiences into the classroom can significantly enhance students’ engagement and retention of knowledge.\",\n",
    "    \"Deforestation in the Amazon rainforest not only threatens biodiversity but also accelerates climate change by releasing stored carbon dioxide.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using ML process for embedding the document body**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"Sample text\"\n",
    "doc_query = \"Sample document\"\n",
    "query_tokens = user_query.lower().split(\" \")\n",
    "query_counter = Counter(query_tokens)\n",
    "doc_tokens = user_query.lower().split(\" \")\n",
    "doc_counter = Counter(doc_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "query_list = []\n",
    "for tk in query_counter.values():\n",
    "    query_list.append(tk)\n",
    "    print(tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "for tokens in query_counter.keys() & doc_counter.keys():\n",
    "    result_list.append(query_counter[tokens] * doc_counter[tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def text_to_vector(text):\n",
    "    # Convert text into a vector using word frequencies\n",
    "    words = text.lower().split()  # Split text into words\n",
    "    return Counter(words)\n",
    "\n",
    "def cosine_similarity_sentence(sentence1, sentence2):\n",
    "    # Step 1: Convert sentences to word frequency vectors\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    \n",
    "    # Step 2: Get the common words between both sentences\n",
    "    common_words = set(vector1.keys()).intersection(set(vector2.keys()))\n",
    "    \n",
    "    # Step 3: Calculate the dot product between the two vectors\n",
    "    dot_product = sum(vector1[word] * vector2[word] for word in common_words)\n",
    "    \n",
    "    # Step 4: Calculate the magnitude of each vector\n",
    "    magnitude1 = math.sqrt(sum([value**2 for value in vector1.values()]))\n",
    "    magnitude2 = math.sqrt(sum([value**2 for value in vector2.values()]))\n",
    "    \n",
    "    # Step 5: Calculate cosine similarity\n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        return 0.0  # Handle zero-vector case to avoid division by zero\n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "\n",
    "# Function to compare a query against a list of sentences\n",
    "def document_similarity(query, sentences):\n",
    "    # Compute similarity between the query and each sentence in the document\n",
    "    similarities = [cosine_similarity_sentence(query, sentence) for sentence in sentences]\n",
    "    return max(similarities), sentences[similarities.index(max(similarities))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"What do you think about uantum computing\"\n",
    "\n",
    "sim_value, relevant_document = document_similarity(user_input, document_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum computing promises to revolutionize data encryption by making previously unsolvable problems computationally feasible.\n"
     ]
    }
   ],
   "source": [
    "print(relevant_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Augmentation using groq model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your query, I recommend the following subject course:\n",
      "\n",
      "**Course Title:** Quantum Computing and Cryptography\n",
      "\n",
      "**Course Description:** This course explores the principles of quantum computing and its applications in cryptography. Students will learn how quantum computers can solve complex problems that are currently unsolvable with classical computers, and how this can be used to break certain types of encryption. The course will also cover the basics of quantum mechanics, quantum algorithms, and quantum cryptography.\n",
      "\n",
      "**Course Outline:**\n",
      "\n",
      "1. Introduction to Quantum Computing\n",
      "\t* Overview of quantum computing and its history\n",
      "\t* Quantum bits and quantum gates\n",
      "\t* Quantum algorithms and their applications\n",
      "2. Quantum Mechanics and Quantum Information\n",
      "\t* Principles of quantum mechanics\n",
      "\t* Quantum states and entanglement\n",
      "\t* Quantum measurement and decoherence\n",
      "3. Quantum Cryptography\n",
      "\t* Introduction to cryptography and encryption\n",
      "\t* Quantum key distribution and secure communication\n",
      "\t* Quantum-resistant cryptography and post-quantum cryptography\n",
      "4. Quantum Algorithms and Complexity\n",
      "\t* Shor's algorithm and factorization\n",
      "\t* Grover's algorithm and search problems\n",
      "\t* Quantum algorithms for linear algebra and optimization\n",
      "5. Quantum Computing and Cryptanalysis\n",
      "\t* Quantum attacks on classical encryption schemes\n",
      "\t* Quantum-resistant cryptography and its applications\n",
      "\t* Future directions in quantum computing and cryptography\n",
      "\n",
      "**Prerequisites:**\n",
      "\n",
      "* Basic knowledge of linear algebra and probability theory\n",
      "* Familiarity with programming languages such as Python or C++\n",
      "* No prior knowledge of quantum mechanics or quantum computing is required\n",
      "\n",
      "**Target Audience:**\n",
      "\n",
      "* Undergraduate and graduate students in computer science, physics, and mathematics\n",
      "* Researchers and professionals in cryptography and cybersecurity\n",
      "* Anyone interested in learning about the intersection of quantum computing and cryptography\n",
      "\n",
      "**Learning Outcomes:**\n",
      "\n",
      "* Understand the principles of quantum computing and its applications in cryptography\n",
      "* Learn how to analyze and design quantum algorithms and cryptographic protocols\n",
      "* Develop skills in programming and simulating quantum systems\n",
      "* Appreciate the potential impact of quantum computing on cryptography and cybersecurity\n",
      "\n",
      "**Recommended Textbooks:**\n",
      "\n",
      "* \"Quantum Computation and Quantum Information\" by Michael A. Nielsen and Isaac L. Chuang\n",
      "* \"Quantum Cryptography and Quantum Key Distribution\" by Valerio Pruneri and Wolfgang Tittel\n",
      "* \"Quantum Algorithms and Quantum Computing\" by Richard J. Lipton and Kenneth W. Regan\n",
      "\n",
      "**Online Resources:**\n",
      "\n",
      "* edX course on Quantum Computing and Quantum Cryptography\n",
      "* Coursera course on Quantum Computing and Quantum Information\n",
      "* Quantum Computing and Quantum Cryptography tutorials on YouTube and GitHub\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import math\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Function to convert text to a word frequency vector\n",
    "def text_to_vector(text):\n",
    "    words = text.lower().split()  # Split text into words\n",
    "    return Counter(words)\n",
    "\n",
    "# Function to calculate cosine similarity between two sentences\n",
    "def cosine_similarity_sentence(sentence1, sentence2):\n",
    "    vector1 = text_to_vector(sentence1)\n",
    "    vector2 = text_to_vector(sentence2)\n",
    "    \n",
    "    common_words = set(vector1.keys()).intersection(set(vector2.keys()))\n",
    "    dot_product = sum(vector1[word] * vector2[word] for word in common_words)\n",
    "    \n",
    "    magnitude1 = math.sqrt(sum([value**2 for value in vector1.values()]))\n",
    "    magnitude2 = math.sqrt(sum([value**2 for value in vector2.values()]))\n",
    "    \n",
    "    if magnitude1 == 0 or magnitude2 == 0:\n",
    "        return 0.0\n",
    "    return dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "# Function to compare query against a list of sentences\n",
    "def document_similarity(query, sentences):\n",
    "    similarities = [cosine_similarity_sentence(query, sentence) for sentence in sentences]\n",
    "    return max(similarities), sentences[similarities.index(max(similarities))]\n",
    "\n",
    "# Streamlit App UI\n",
    "st.title(\"Document Similarity Checker with Study Recommendation\")\n",
    "\n",
    "# Text input or file upload\n",
    "document_body = st.text_area(\"Enter document text or paste multiple sentences (one per line):\")\n",
    "uploaded_file = st.file_uploader(\"Or upload a text file\", type=\"txt\")\n",
    "\n",
    "# User input for query\n",
    "user_query = st.text_input(\"Enter a query to compare against the document:\")\n",
    "\n",
    "# Add a submit button\n",
    "if st.button(\"Submit\"):\n",
    "    if uploaded_file:\n",
    "        document_body = uploaded_file.read().decode(\"utf-8\")\n",
    "\n",
    "    if document_body and user_query:\n",
    "        sentences = document_body.split('\\n')\n",
    "        sim_value, relevant_document = document_similarity(user_query, sentences)\n",
    "        \n",
    "        st.write(f\"Most relevant document: {relevant_document}\")\n",
    "        st.write(f\"Cosine similarity score: {sim_value:.4f}\")\n",
    "\n",
    "        # ChatGroq model setup for recommendations\n",
    "        llm = ChatGroq(\n",
    "            model=\"llama-3.1-70b-versatile\",\n",
    "            temperature=0,\n",
    "            groq_api_key=groq_api_key,\n",
    "            max_tokens=None,\n",
    "            timeout=None,\n",
    "            max_retries=2,\n",
    "        )\n",
    "\n",
    "        prompt_extract = PromptTemplate.from_template(\n",
    "           \"\"\"\n",
    "           You are a chat bot making recommendation for studies. A recommended subject course is: {sim}.\n",
    "           Given a query: {query}\n",
    "           Compile a recommended subject course for the user, which is based on the user's query.  \n",
    "           \"\"\"\n",
    "        )\n",
    "\n",
    "        json_parser = JsonOutputParser()\n",
    "        chain = prompt_extract | llm\n",
    "        response_chain = chain.invoke(input={\"sim\": relevant_document, \"query\": user_query})\n",
    "\n",
    "        # Display the LLM response\n",
    "        st.write(\"Recommended study course:\")\n",
    "        st.write(response_chain.content)\n",
    "    else:\n",
    "        st.write(\"Please provide both document text and a query.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Augmentation using LLAMA2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"\"\"\n",
    "# You are a chat bot making recommendation for studies. A recommended subject course is: {relevant_document}.\n",
    "# Given a query: {user_input}\n",
    "# Compile a recommended subject course for the user, which is based on the user's query.  \n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "# data = {\n",
    "#         \"model\": \"llama2\",\n",
    "#         \"prompt\": prompt.format(user_input=user_input, relevant_document=relevant_document)\n",
    "# }\n",
    "\n",
    "# headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# response = requests.post(url, data=json.dumps(data), headers=headers, stream=True)\n",
    "\n",
    "# full_response = []\n",
    "# try:\n",
    "#   for line in response.iter_lines():\n",
    "#     if line:\n",
    "#       decoded_line = json.loads(line.decode(\"utf-8\"))\n",
    "#       print(decoded_line)\n",
    "#       # full_response.append(decoded_line[\"response\"])\n",
    "# finally:\n",
    "#   response.close()\n",
    "      \n",
    "\n",
    "# curl http://localhost:11434/api/chat -d '{\n",
    "#   \"model\": \"llama3.2\",\n",
    "#   \"messages\": [\n",
    "#     { \"role\": \"user\", \"content\": \"why is the sky blue?\" }\n",
    "#   ]\n",
    "# }'\n",
    "\n",
    "# response = ollama.chat(model='llama2', messages=[\n",
    "#   {\n",
    "#     'recommended_course': sim,\n",
    "#     'user_query': my_query,\n",
    "#   },\n",
    "# ])\n",
    "# print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, score in enumerate(sims):\n",
    "#     print(f\"Sentence {idx + 1}: {document_body[idx]}\")\n",
    "#     print(f\"Similarity Score: {score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"\"\"\n",
    "# You are a chat bot making recommendation for studies. A recommended subject course is: {sim}.\n",
    "# Given a query: {query}\n",
    "# Compile a recommended subject course for the user, which is based on the user's query.  \n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "# data = {\n",
    "#         \"model\": llm,\n",
    "#         \"prompt\": prompt.format(query=user_input, sim=relevant_document)\n",
    "# }\n",
    "\n",
    "# # generate a response\n",
    "# curl http://localhost:11434/api/generate -d '{\n",
    "#   \"model\": \"llama3.2\",\n",
    "#   \"prompt\":\"Why is the sky blue?\"\n",
    "# }'\n",
    "\n",
    "# # chat with a model\n",
    "# curl http://localhost:11434/api/chat -d '{\n",
    "#   \"model\": \"llama3.2\",\n",
    "#   \"messages\": [\n",
    "#     { \"role\": \"user\", \"content\": \"why is the sky blue?\" }\n",
    "#   ]\n",
    "# }'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
